{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47e8bd1-89b4-4abe-8e03-88e3b1e2b83b",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9aeb2-164f-413c-a372-2525bc7eb038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import nltk\n",
    "import requests\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a5431-9cca-49c7-b6c0-dbf28d52bbfd",
   "metadata": {},
   "source": [
    "## 2. Scrape Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71318b83-b097-4112-9fbb-276f97ff7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape: Extracting the Information from Web-site.\n",
    "def scrape_website(url, label):\n",
    "\n",
    "    # Mimic like a real browser by sending a User-Agent header (some websites block automated requests).\n",
    "    headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Request Web-site.\n",
    "        response = requests.get(url, headers=headers, timeout=45)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to load {url}. Status code: {response.status_code}\")\n",
    "            return \n",
    "    \n",
    "        # Parse HTML-document.\n",
    "        soup = BeautifulSoup(response.content, 'html.parser') \n",
    "\n",
    "        # Extract Information.\n",
    "        title = soup.title.string if soup.title else \"\" \n",
    "\n",
    "        # Extract the meta description (if present).\n",
    "        meta_description = \"\" \n",
    "        meta_tag = soup.find('meta', attrs={'name': 'description'}) \n",
    "        if meta_tag and 'content' in meta_tag.attrs:\n",
    "            meta_description = meta_tag['content']\n",
    "\n",
    "        # Paragraph Content.\n",
    "        main_content = \"\".join([p.get_text(strip=True) for p in soup.find_all('p')])\n",
    "\n",
    "        # Headers\n",
    "        headers = \"\".join([h.get_text(strip=True) for h in soup.find_all(['h1', 'h2', 'h3'])])\n",
    "\n",
    "        \n",
    "        return{\n",
    "            'url': url,\n",
    "            'title': title,\n",
    "            'meta_description': meta_description,\n",
    "            'content': main_content,\n",
    "            'headers': headers,\n",
    "            'category' : label\n",
    "        }\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0299006-e30b-425c-bd80-ed4f1529cd87",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198ea27c-05cb-41be-992c-13260d1ddac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \n",
    "    # Gather whole information(handling NaN)\n",
    "    df['text'] = df['title'].fillna('') + \" \" + df['meta_description'].fillna('') + \" \" + df['content'].fillna('') + \" \" + df['headers'].fillna('') + \" \" + df['category'].fillna('')\n",
    "\n",
    "    # Convert to lower-case.\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    \n",
    "    # Remove punctuation (.,?!-'\").\n",
    "    df['text'] = df['text'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebed4ec-2ebb-4dee-bbce-83959efb9184",
   "metadata": {},
   "source": [
    "## 4. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a578bdd9-e5a4-45c0-948d-98afb7d0ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_features=10000)\n",
    "    features = vectorizer.fit_transform(df['text']) \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1c17b-4eea-48e6-b319-bab7433ce512",
   "metadata": {},
   "source": [
    "## 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "496d8d9e-3f5e-4838-803e-09c29d249a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Model\n",
    "def train_model(features, labels):\n",
    "    # Note: \n",
    "    # We are classifing websites based on text they contrain.\n",
    "    # model = MultinomialNB() # Naive-bayers text classifier.\n",
    "    model = RandomForestClassifier()\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(features, lables, test_size=0.2, random_state=42) \n",
    "    # 'stratify' makes sure that in test-set all categories have same same/mix propotion. So that they are fairly tested.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=42) \n",
    "    \n",
    "    model.fit(X_train, y_train) \n",
    "    \n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b4e94f-708c-4683-8481-7089d3784ef8",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb723ab-582c-4832-a864-7df3d878aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b58376-6f34-40c0-b45d-6e0ab461e412",
   "metadata": {},
   "source": [
    "## 7. Save and Load Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d72e84e-56f5-4749-a3b0-c5b3eb123878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, filename):\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c33316-7ed2-435c-9279-e675a8ffe3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_csv(filename):\n",
    "    return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe3c99ca-4757-4732-97f8-37ad64436eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously scraped data from scraped_data.csv\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automotive       1.00      1.00      1.00         2\n",
      "   e-commerce       1.00      1.00      1.00         4\n",
      "    education       0.67      0.80      0.73         5\n",
      "entertainment       0.60      1.00      0.75         3\n",
      "      finance       1.00      0.50      0.67         2\n",
      " food & drink       0.83      1.00      0.91         5\n",
      "       health       1.00      0.75      0.86         4\n",
      "    lifestyle       1.00      0.75      0.86         4\n",
      "         news       1.00      0.80      0.89         5\n",
      "  real estate       1.00      1.00      1.00         3\n",
      "       sports       1.00      1.00      1.00         5\n",
      "   technology       0.75      0.75      0.75         4\n",
      "       travel       1.00      1.00      1.00         2\n",
      "\n",
      "     accuracy                           0.88        48\n",
      "    macro avg       0.91      0.87      0.88        48\n",
      " weighted avg       0.90      0.88      0.88        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_file = 'scraped_data.csv'\n",
    "    \n",
    "if not os.path.exists(output_file):\n",
    "    # Scrape and preprocess data\n",
    "    df = pd.read_csv('data.csv')\n",
    "    urls = df['url'].tolist()\n",
    "    labels = df['category'].tolist()\n",
    "    data = []\n",
    "        \n",
    "    for url, label in zip(urls, labels):\n",
    "        website_data = scrape_website(url, label)\n",
    "        if website_data:\n",
    "            data.append(website_data)\n",
    "        time.sleep(2)  # Add a delay between requests\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    # Shuffle-data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    # Data Pre_processing\n",
    "    df = preprocess_data(df)\n",
    "        \n",
    "    # Save the scraped and preprocessed data\n",
    "    save_to_csv(df, output_file)\n",
    "else:\n",
    "    # Load the previously scraped data\n",
    "    print(f\"Loading previously scraped data from {output_file}\")\n",
    "    df = load_from_csv(output_file)\n",
    "\n",
    "# Extract features\n",
    "features = extract_features(df)\n",
    "\n",
    "# Train and evaluate the model\n",
    "model, X_test, Y_test = train_model(features, df['category'])\n",
    "evaluate_model(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc3196-49e7-4953-b551-9da59c267ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web-mining",
   "language": "python",
   "name": "web-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
